\begin{document}

\chapter{Introduction}
\section{Research questions}

Due to its cross-platform capabilities, Progressive Web Apps seems like a promising alternative to native development. However, this shouldn't come at the cost of app performance and user experience, especially in regards to smoothness.
Thus, this paper will aim at answering the question : 
\begin{center}
    \textit{Can Progressive Web Apps be as smooth as Mobile Applications ?}
\end{center}
Which raises the following sub-questions: 
\begin{enumerate}
    \item What metrics are relevant to compare the smoothness of Mobile and Progressive Web Apps?
    \item What tools are available to measure those metrics ?
\end{enumerate}

\iffalse
Primary research question : 
\newline \textit{How efficient can Progressive Web Apps be compared to a Native Android Application?}
\newline
Secondary Research questions :
\\1. \textit{How can we compare Progressive Web Apps and Mobile Apps ?}
\newline \indent
1.1 \textit{What metrics are relevant to compare Progressive Web Apps and Mobile Apps ?}
\newline \indent  
1.2 \textit{What tools are available to measure those metrics?}
\newline
\\2. \textit{Are Progressive Web Apps more efficient than Mobile Apps with regards to the first question?}
\fi

Due to its cross-platform capability, Progressive Web Apps seems like a promising alternative to native development. However, this shouldn't come at the cost of app performance and user experience, especially in terms of the app smoothness and rendering capacity.
Thus, this paper will aim at answering the question : 
\begin{center}
    \textit{Are Progressive Web Apps more performant than Mobile Apps in terms of rendering capacity ?}
\end{center}
Which can be divided into the following sub-questions: 
\begin{enumerate}
    \item How can we compare Progressive Web Apps with Mobile Applications?
    \item What tools are available to measure the relevant metrics ?
\end{enumerate}

\chapter{Background}
\section{Mobile Applications}
\subsection{Development}

React Native, Ionic and PhoneGap are one of the most popular frameworks used today \cite{CrossPlatform_study}.

\section{Progressive Web Apps}
\subsection{Academic research}

Since June 2019, more than half of Web traffic comes from mobile devices. \cite{WebTrafficData}

    \cite{smoothnessQoE} build a model to evaluate the smoothness of smartphones. This model focuses on two major indexes : the maximum frame interval and the total number of frames in different key behavior scenarios (phone calls, browsing the web, playing games, etc). Those frames are defined as the interval of time between user input and response time of several key display events measured with a camera. %To check this frame definition
    
    \cite{PWAbc_responsetime} measured the response time between an Android app and a React PWA when accessing the Camera and Maps. The response time was measured 54 times for each scenario. The results show that Native are faster for accessing the camera, though PWAs are making progress in that regard. However, PWAs are faster regarding geolocation and map rendering.
    
    \cite{YbergViktor2018NPaU} focused on the user experienced of PWAs and measured several performance metrics: load times (Polymer, React, Preact), start-up times (native app, Polymer with and without browser in memory), Lighthouse performance audit (Polymer), list rendering times (PWA). He concluded that PWAs provided a good enough user experience for information access apps, though PWAs are not fully supported on every platform and web browser.
    
    \cite{PWApossibleUnifer}, followed by \cite{Biorn-Hansen2} shows a lack of academic research on the subject. \cite{PWApossibleUnifer} developped three apps using the Hybrid, Interpreted and PWA approach and compared their startup speed, app size and rendering speed. They conclude that PWA have a lot of potential to unify web and mobile development, though some limitations remains (lacking some hardware access, and browser support on some platform).
    
    \cite{Biorn-Hansen2} developed 5 apps: a PWA, a native app written in Kotlin, an Ionic hybrid app, an Interpreted React Native app and a cross-compiled Xamarin app. Again, they measure the app size, the activity launch time and the time from app icon to toolbar rendering. They reconfirmed the potential of PWAs to have an important part in futur Mobile development, depending on iOS support. They are extremely small compared to other apps, and render content fast. Although they lack some hardware access, they are also the only ones testable before install. 
    
    \cite{SW_and_energy} studied the energy impact of service workers on PWAs. Their results showed no significant energy impact from service workers. However, it also showed different energy consumption of each PWAs
    
    \cite{JohannsenFabian2018PWAa} studied how turning a regular web app into a PWA affects the code complexity in Angular. It concluded that the main increasing factor is the understanding of the new concepts behind the service workers, but automated PWA tooling can decrease it.
    
    \cite{Pride_Prejudice} identified several security threats regarding PWAs
    
    \cite{bac_pwa_comparison} found that PWAs had a slower performance than regular web apps (with lighthouse performance metrics)
    
    \cite{PWA_UX_comparison_study} conducted an analysis of user experience when interacting with a regular web app, a native Android app and a PWA. The 8 participants had an overall good user experience on every platform.
    
    \cite{bac_pwa_performance} studied loading performance (first paint, etc) of PWA in comparison to Apache Cordova app and native android. The results differ between phones %Conclusion noot very clear on this one
    
    \cite{emulating_native_w_crossplatform} compared features from a cross-platform app, a native Android app and a PWA. They were also compared in a qualitative and a qualitative user studies. No real difference was found between the applications. The React Native app performed a little better on the quantitative study, and the PWA performed a little better on the qualitative study.
    
    \cite{PWADatabase} compare performance of same app developed multiple times with different parameters (framework, service-worker, optimization, etc)
    
    \cite{PWAapplicability} compared the same app developed 4 times : a) as a native iOS, b) a native Android, c) a web app and d) a pwa in regards to First Paint and Energy consumption. Regarding the First Paint metric, the PWA performed better against the web app and the native Android app. The difference with iOS might be because of the incomplete support of PWA on iOS. As for energy consumption, PWA seemed to consume less energy, but the number of experiments was not enough to really confirm that.

\section{Profiling tools}

In order to answer the answer the research question, several metrics will be measured across a number of experiments. The most important one is information regarding the frames produced by the application
%, with a target rate of 60 frame per second \citationneeded \todo{Why?}
. Other metrics will be measured to assess the rendering capacity of the applications : the \%CPU usage of the application as well as the memory used by the GPU. This section covers the tools available to automatically collect the data needed as well as the tools chosen for this study.  


\subsection{Android}
However, this tool is not suited for automatic data collection as the results are only available in charts. Moreover, it can have a high overhead \cite{nanoscope} making the collected data less precise.

\paragraph{}
\textbf{Android Debug Bridge} \cite{adb} is a command-line tool used to communicate with an Android device (physical or emulator) from a computer. It can be used to list available devices (command \textit{devices}), forward requests (command \textit{forward} or execute commands on the device (command \textit{shell}). It will be widely used during this study. 

\paragraph{}
\textbf{Dumpsys} \cite{dumpsys} used with \textit{adb shell} provides information about the device's system services. A lot of different services (thus information) is available through this command-line tool, for example the network, the battery usage, input events, \red{etc}. The most interesting services for this study are: \todo{Rephrase} 
\begin{itemize}
    \item \textit{gfxinfo} which provides information regarding the animation such as jank rate (percentage of frames considered janky ie not meeting the 60fps threshold), total number of frames since recording, etc. It can be used with two options : \textit{framestats} which gives additional information about the frame timestamps, and \textit{reset} which reset the information recorded until now. This information is retrieved by Android framework during the application run-time.
    
    \item \textit{cpuinfo} gives the \%CPU usage of each process running during a given interval of time. The system computes this information from the proc/stat/ files (similar to the files of the same name found on Linux systems) and displays it as the percentage of CPU time used over the total CPU time available in one CPU core with a 0.1\% precision. The information is updated whenever the system needs it and  \todo[color=cyan!20]{Do I cite the source code for that ?} \todo{Yes:)} at least every 30min so the output is not always up-to-date.  
    
    \item \textit{meminfo} takes a snapshot of the memory allocation and outputs the data in details. The main field of interested displays by this command is the amount of memory used for graphics buffer queues. Coincidentally, it also checks the information contained by \textit{cpuinfo} is up-to-date. Thus, it is also used in the experiments to update \textit{cpuinfo}
\end{itemize}

\paragraph{}
\textbf{Top} comes from the Linux command-line of the same name, but with limited options. It displays the process activity in real-time (\%CPU, memory used and other). Its source of information is the same as dumpsys. However, the \%CPU displayed is the percentage of CPU time used over the total CPU time available in the device, with a 1\% precision. This makes it less accurate especially for processes that doesn't consume a lot of CPU. Thus, this command-line was discarded in favor of dumpsys.

\paragraph{}
\textbf{Systrace} \cite{systrace} records a device activity during a short period of time and outputs it in the form of an html file. The file can be viewed on Chrome Browser and displays a timeline of events for each threads running during the recording. The events displayed depends on the categories selected when starting the recording. This tool isn't suitable for automated experiments but can be really helpful to understand the cause of a bottleneck or, as it is the case in this study, understand how Android system works.

\paragraph{}
\textbf{Systrace} \cite{systrace} records a device activity during a short period of time and outputs it in the form of an html file. The file can be viewed on Chrome Browser and displays a timeline of events for each threads running during the recording. The events displayed depends on the categories selected when starting the recording. This tool isn't suitable for automated experiments but can be really helpful to understand the cause of a bottleneck or, as it is the case in this study, understand how Android system works.

\paragraph{}
\textbf{Monkeyrunner} \cite{monkeyrunner} is a tool used to interact with an Android device from a Python script. Aside from sending events and executing \textit{adb shell} commands, it can also take screenshots to test the app. This tool was used to automate the experiment and remove the variables introduced by human interaction from the experiments. 

\subsection{Chrome}

As Progressive Web Apps are after all web applications that runs on the browser, many of the tools available depends on the browser running the app. Thus, the tools presented here may only apply to apps running on Chrome.

\paragraph{}
\textbf{Chrome DevTools} is a set of developer tools available in the Chrome Browser in order to inspect a page on the browser (the network, the performance, the memory, the elements, etc). The main tool of interest here is the \textit{Performance} panel \cite{chrome_devtools_perf} which can record certain events during a period of time and display a lot of information from these events. Among the features of interest are : the display of the duration of a frame as well as the CPU time used to compute it, a CPU, an FPS and a memory chart in addition to a timeline of different events recorded.

\paragraph{}
\textbf{Lighthouse} \cite{lighthouse} is an automated  tool used to assess any web page's quality but mainly targeting Progressive Web Apps \cite{PWApossibleUnifer}. It is available from the \textit{Audits} panel on Chrome Devtools and can retrieve a large number of metrics from an automated recording. Those metrics are classified into five different groups: Performance, Accessibility, Best Practices, Search Engine Optomization (SEO) and Progressive Web Apps, and give an overall score from 0 to 100. It was often used in previous research on PWA \cite{}

\section{Rendering pipeline}

\subsection{Android}
Multiple Application Renderers can communicate with SurfaceFlinger at the same time.   When an application needs to display something on the screen, it pushes a 'surface' to a BufferQueue shared with SurfaceFlinger. Every once in a while, usually in synchronization with the screen refresh rate, SurfaceFlinger wakes up and look into the BufferQueues.

\subsection{Chrome}
However, some stages can be skipped depending on the change between two frames.

\section{Problem analysis}
In the light of the background described above, this sections provides additional motivation and limitations for the research questions. 
\paragraph{}
\textbf{Motivation} \newline

Previous research about Progressive Web Apps performance focused mainly on the performance at start-up (loading time, first paint) but none was found that studied the rendering performance during use. To my best knowledge, this research will be the first to do so.

\medskip
\textbf{Limitations} \newline
As stated above, Android applications and Web Applications on Chrome share two components of the display pipeline (SurfaceFlinger and the Hardware Composer) but differ greatly in the Application Renderer. Thus this research will focus on comparing the smoothness of Android applications and Progressive Web Apps in regards to this last component. 

Thus, this paper will analyze smoothness performance of the applications by looking at the average frame duration, as well as CPU and memory used to compare the resources used. 

\iffalse
However, at the time of writing no study was found that examined the rendering performance of Progressive Web Apps. While it is important for the user that the app launches quickly \cite{launch_time}, it is also important that the app remains smooth during the time of use. \newline
Thus, this paper will try to address this issue and study the smoothness of mobile applications and progressive web apps.

Most of the time, the smoothness of an application is associated with its responsiveness i.e. how quickly it can respond to user input.

As defined by nanana, "the principle of smoothness states that objects must change in a continuous fashion, which reduces cognitive load by removing large and unexpected changes in visual information presented to the user". In other words, a smooth animation changes frames and with little changes between them 

In this work, the smoothness of an application is defined as how quickly it can change the display

\paragraph{}
The smoothness of a mobile application is usually evaluated using the frame rate, or FPS for frame rate per second \cite{smoothnessQoE} \todo[inline]{It would be good to clarify what is smoothness and fluidness}. Though as Biørn-Hansen et al. pointed out while studying animation performance in mobile applications, the FPS metric does not give much insight about the fluidness of a user interface where animations run only during a short amount of time and the remaining time is spent idle waiting for new inputs.
\newline
Thus, this paper will analyze the smoothness performance of the applications by looking at the average frame duration, as well as CPU and memory used to compare the resources used. 
\fi

\chapter{Methodology}
\section{Comparing the Rendering Process}
   
    The background section presented an overview of Android's Garphics pipeline, with the Application Renderer itself divided into 7 stages : input handling, animation, measurement and layout, draw, sync and upload, issue commands, process and swap buffers. 
    
    It is possible to extract detailed information about an Android application frames thanks to the command \textit{adb shell dumpsys gfxinfo framestats}. This outputs multiple graphic information, such as total number of frames rendered, number of janky frames
    
    We can observe some of those stages in a Systrace recorded with the command: \textit{python systrace.py sched gfx view app -a [package-name] -o [output-file]}.
    
    \begin{figure}[!ht]
        \includegraphics[width=15cm]{kththesis/Figures/android_systrace_frame.jpg}
        \caption{Application Renderer on Android}
        \label{fig:android_systrace}
    \end{figure}
    
    
    \subsection{Chrome's pipeline}
    \todo[inline, color=cyan!20]{Describe Chrome's pipeline model and how I came up with it}
       As was described in the Background chapter, Chrome contains several processes, including the Browser Process, the Renderer and the GPU Process.
       
       To automate tracing, the Chrome Devtools Protocol was used. Its experimental domain 'Tracing' allows to record the same events as Chrome's Tracing tool. This enable the automation of both tracing and event processing to extract a model. \newline
The resulting model is presented in Figure \ref{fig:chrome_graphics_simple}. For a more detailed version with all the events tracked to know if a frame is truly rendered, see Annex \ref{?}.

\item The VizCompositorThread, probably because of a VSYNC event that happened previously, asks for a new frame to the Renderer process with the event 'IssueBeginframe' which contains a bind\_id.
    \item The Compositor thread of the Renderer process discard or accept it with the event 'ReceiveBeginFrame' which contains the same bind\_id. This event also call 'Scheduler::BeginFrame' which contains a sequence\_number necessary to follow the frame afterwards.
    \item The Compositor may ask a new main frame, and schedules the next step depending on the urgency of the frame with the event Scheduler::BeginImplFrame containing the same sequence\_number. The event asking for a new main frame contains a begin\_frame\_id useful to follow the frame in the thread CrRendererMain.
    \item If a new main frame was asked, it is compiled in CrRendererMain. The pipeline stages Styling, Layout, Compositing, pre-Painting and Painting are computed here if necessary.
    \item If a new main frame was committed by CrRendererMain, Tiling and Raster may be computed by the Compositor and other threads if necessary. Then, it is activated: the new main frame replaces the old one in the Compositor.
    \item The deadline of the scheduler is up: Scheduler::OnBeginImplFrameDeadline is called with the same sequence\_number as the beginning. This event itself calls several other events : GenerateRenderPass, GenerateCompositorFrame and SendCompositorFrame containing a bind\_id and LayerTreeHost::PrepareToDraw containing a SourceFrameNumber referencing the main frame used for this frame. SendCompositorFrame is not always detected but is an important event to track.
    \item The VizCompositorThread receives the CompositorFrame from the Renderer, and maybe wait for more. It then aggregates the surfaces ie the CompositorFrames into a single frame. It also assigns a put\_offset to the frame. It is not an id per say as it is not unique but the reuse of numbers are spaced enough to use it as IDs.
    \item The main thread of the GPU receives the frame and swap buffers for SurfaceFlinger. Since it is 
    
    \subsection{Method of comparison}
    \todo[inline, color=cyan!20]{Conclusions on how to compare both pipelines: a) definition of a frame b) benchmark apps used}
    
    \iffalse

A Main Frame starts to compute the frame at \textit{BeginMainFrame} timestamp. A Basic Frame which re-uses a previous main frame only starts computing at the beginning of 'ProxyImpl::ScheduleActionDraw' event. 

    To summarize, on one hand Android's pipeline is pretty straightforward and easy to follow : the OS sends VSync signals that depends on the device refresh rate, asking everything on the foreground to render a frame. In response, the UI thread calls Choreographer\#doFrame which handles callbacks for input and animation before doing some sizing and layout. The Choreographer then hands what it computed to the RenderThread which issues the draw commands and swap the buffers for SurfaceFlinger.


On the other hand, Chrome's pipeline is much less consistent and depends on a lot of parameters. We know that the VizCompositorThread also calls the Choreographer almost at each Vsync though it stops after the animation callbacks. As it is also the thread emitting 'IssueBeginFrame' events, those events are most likely linked, though I don't know when this IssueBeginFrame event is emitted compared to the Choreographer.

Thus, it is meaningless to compare Chrome's frames with Android's from the start of Choreographer or the start of Vsync.

Another point against doing this is the the input events. Those are always handled on Android inside the Choreographer, just before computing the frame. On Chrome, however, they are handled asynchronously and thus an input can affect a frame currently being drawn or start a new one.

This leaves us with comparing the amount of time they spent on computing the frame. For Android, it starts with traversal, and can be accessed with the PerformTraversalStart timestamp. For Chrome, it is a little more complicated as a 'frame' for Android, that is a graphical buffer swapped for SurfaceFlinger, consists of several frames computed in parallel and combined on Chrome's Pipeline. \newline

As a Browser frame on PWA represents things usually handled by the application on Android like the scrollbar or refresh animation, and it also leads to a BufferSwap, 
For a 'Main frame', the computation starts with the \textit{BeginMainFrame} timestamp. For a 'Basic frame' which uses an old main frame as a baseline, it starts with the event 'ProxyImpl::ScheduleActionDraw'. 

For a Basic frame which reuse a Main frame already drawn, I believe the computation starts inside ProxyImpl::ScheduleActionDraw. For a basic frame with a new Main frame, it should start at 'BeginMainThreadFrame' event. 

As a Buffer swap consists of both a Basic frame and a Browser frame, and a Browser frame can trigger a Buffer swap by itself, the question is do we count them as part of the PWA's frame or not. If, as I suppose, the Browser frame displays things like the scrollbar, I believe we should count them as a PWA's frame as these displays are usually handled by the app on Android. 

Thus, the most meaningful comparison, in my opinion, is the time between the timestamps PerformTraversalStart->FrameCompleted on Android and PrepareToDraw/BeginMainThreadFrame(if new main frame)->FrameCompleted of the Compositor frame of the Browser frame on Chrome (depending which took longest for the corresponding Buffer swap).

\fi
    
\section{Comparing CPU and Memory}
    \subsection{Android and Chrome tools}
    \todo[inline, color=cyan!20]{Describe available tools on Android and Chrome}
    \todo[inline]{Move to Background}
    \subsection{Evaluating Chrome tools}
    \todo[inline, color=cyan!20]{Describe Experiments used to compare Android and Chrome tools, and their results}
    \subsection{Evaluating Emulators}
    \todo[inline, color=cyan!20]{Explain why Emulators are no good for evaluating CPU and Memory}
\section{benchmark and protocol}

\iffalse
The smoothness metric defined previously depends in Progressive Web Apps on the rendering path taken by the frame. Thus, the benchmark application will have 2 features : one favouring Main Frames and the other favouring Basic Frames. The easiest way to trigger a Main Frame is to change the content of the screen. This can be done with a single click. A Basic Frame is basely triggered  
\fi
\subsection{script implementation}
\iffalse
We will focus on the fluidity of the apps that can be defined with Frame Per Second (FPS) rate.
Thus, we will compare the FPS rate of a Native Android Application and a Progressive Web App, as well as with a benchmark consisting of : 
    - an app displaying different image/texts every 16/17ms
    - an app with more effort on the CPU : modification of the same pictures/texts or new pictures/texts generated randomly.

\newline
\fi

We will measure FPS, CPU and Memory usage to see the impact of CPU and Memory usage in the fluidity of the app.
\newline
We will focus on the fluidity of the apps that can be defined with Frame Per Second (FPS) rate.
Thus, we will compare the FPS rate of a Native Android Application and a Progressive Web App, as well as with a benchmark consisting of : 
    - an app displaying different image/texts every 16/17ms
    - an app with more effort on the CPU : modification of the same pictures/texts or new pictures/texts generated randomly.
\newline

We will measure FPS, CPU and Memory usage to see the impact of CPU and Memory usage in the fluidity of the app.
\newline

\subsection{Scripts implementation}
\todo[inline]{Explain your technical contributions}

\end{document}